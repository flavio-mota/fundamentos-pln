{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIC260 - Introdução ao Processamento de Linguagem Natural.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wpfUoquTmPhf",
        "ZvwUgtdpsbMq"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNM+PLxu4fkk9XGJCblSjLK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flavio-mota/fundamentos-pln/blob/master/CIC260_Introdu%C3%A7%C3%A3o_ao_Processamento_de_Linguagem_Natural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTkIQCYUkmEH"
      },
      "source": [
        "# Introdução ao Processamento de Linguagem Natural (PLN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H_sVHX_ky2H"
      },
      "source": [
        "## Objetivos gerais:\n",
        "\n",
        "\n",
        "*   Apresentar noções básicas de sobre o que é o PLN\n",
        "*   Criar funções simples que realizem a limpeza e análise de textos\n",
        "*   Realizar algumas análises quantitativas\n",
        "*   Aplicar etiquetagem morfossintáticas às palavras do corpus\n",
        "*   Geração de gráficos\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpfUoquTmPhf"
      },
      "source": [
        "## Começando com uma análise simples de textos\n",
        "\n",
        "Vamos criar uma variável chamada `sentenca` e armazenar uma pequena frase nela:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWtvbYS4Jruy"
      },
      "source": [
        "sentenca = 'A raposa rápida salta sobre o cão preguiçoso'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJGDtk6DnF-g"
      },
      "source": [
        "Vamos verificar agora a ocorrência de uma palavra dentro da sentença:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDze0baJkl0A",
        "outputId": "33cf289e-3922-4122-a8b7-38ebd81db569"
      },
      "source": [
        "'rápida' in sentenca"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUxshQpynaTf"
      },
      "source": [
        "O código acima retorna `True`, indicando que a palavra 'rápida' existe dentro da sentença. Se fosse utilizada a palavra 'gato', o retorno seria `False`, uma vez que essa palavra não existe na frase.\n",
        "\n",
        "Agora, vamos retornar uma determinada palavra da frase através de sua posição. No exemplo a seguir, o código retorna a palavra na 5ª posição da sentença:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EmhMvfzQnZVP",
        "outputId": "e8a85fa4-401e-4e80-c6c4-ce347467ac5a"
      },
      "source": [
        "sentenca.split()[4]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sobre'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKeOueBfpR4f"
      },
      "source": [
        "Para exibir uma determinada palavra de trás para frente, podemos utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6aXZayEHpKpY",
        "outputId": "ea63799d-d1de-47cb-cd8a-0104fa923cc8"
      },
      "source": [
        "sentenca.split()[1][::-1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'asopar'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_fZCQb0rFaH"
      },
      "source": [
        "Para exibir toda a sentença invertida:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zjkPO75IrJPQ",
        "outputId": "abae8ffc-79dc-43a1-b974-0db8b6c081e3"
      },
      "source": [
        "sentenca[::-1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'osoçiugerp oãc o erbos atlas adipár asopar A'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pABt5xPpojE"
      },
      "source": [
        "Vamos concatenar a primeira e a última palavra da sentença:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hjNCG7ZpdPl",
        "outputId": "193f5c77-4d45-44d8-9b19-02ddddc07575"
      },
      "source": [
        "palavras = sentenca.split() #Vamos criar uma variável para armazenar as palavras\n",
        "primeira_palavra = palavras[0] #Recuperamos a primeira palavra (posição 0)\n",
        "ultima_palavra = palavras[len(palavras)-1] #Recuperamos a última palavra (tamanho do vetor de palavras menos 1)\n",
        "concatenar_palavras = primeira_palavra + ultima_palavra\n",
        "print(concatenar_palavras)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apreguiçoso\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXM3l0GPqhhS"
      },
      "source": [
        "Para encontrar as palavras que estão em posições pares da sentença, podemos utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I51LBYStqb3g",
        "outputId": "85659fb2-1843-486c-90ff-1cdf1598dd4d"
      },
      "source": [
        "[palavras[i] for i in range(len(palavras)) if i%2 == 0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'rápida', 'sobre', 'cão']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFl-Q44FuWoe"
      },
      "source": [
        "## Um breve parênteses: A biblioteca NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLTQoTRLud36"
      },
      "source": [
        "A NLTK (**N**atural **L**anguage **T**ool**K**it) é uma biblioteca do python que oferece uma infinidade de recursos para o tratamento de dados textuais. Ela conta com uma excelente documentação, que inclui passo a passo a utilização dos recursos. Um diferencial dessa biblioteca é a disponibilidade de recursos linguísticos em português. Vamos utilizar alguns desses recursos a seguir.\n",
        "\n",
        "Link para documentação: [NLTK](https://www.nltk.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvwUgtdpsbMq"
      },
      "source": [
        "## Tarefas do PLN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znK2I9AXstb0"
      },
      "source": [
        "Ao trabalhar com textos no PLN, diversas tarefas podem ser executadas, como a *tokenização*, limpeza do texto, etiquetagem, contagens de palavras, *stemming*, etc. Vermos algumas dessas tarefas a seguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qREnH9AJsjUz"
      },
      "source": [
        "### Tokenização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6HUA9RUykxr"
      },
      "source": [
        "A *tokenização* é o processo de dividir as sentenças em palavras. Considere a frase:\n",
        "> \"Eu estou lendo um livro.\"\n",
        "\n",
        "A tarefa de *tokenização* tem como objetivo extrair as palavras (ou tokens) dessa sentença, produzindo:\n",
        "> 'Eu', 'estou', 'lendo', 'um', 'livro', ' . '\n",
        "\n",
        "Esse tipo de extração é chamada de 'unigrama', uma vez que separa uma palavra por vez. Entretanto, é possível realizar a extraçã de dois ou três *tokens* por vez. Se são 2 *tokens* por vez, chamamos de **bigramas**. Se são 3, **trigramas**. Dependendo da necessidade, podemos ter **n-gramas**, sendo n um número natural.\n",
        "\n",
        "> **n-gramas** são sequências de n palavras de um texto.\n",
        "\n",
        "No PLN trabalhamos com *tokens* por questão de conveniência, já que temos a tendência de realizar as análises palavra por palavra.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH2TSMCJzPMi"
      },
      "source": [
        "Vamos realizar a tokenização de uma sentença simples. Para isso vamos utilizar um módulo da NLTK que facilita esse processo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFXhK8S1q-jw",
        "outputId": "c03e0c36-78f4-4475-d535-869a48d4d0b6"
      },
      "source": [
        "import nltk #importando a biblioteca\n",
        "from nltk import word_tokenize #importando o módulo word_tokenize\n",
        "nltk.download('punkt') # baixando o recurso de pontuação, necessário para realizar a tokenização"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHUQsbdZzl_C"
      },
      "source": [
        "palavras = word_tokenize('Eu estou aprendendo sobre os fundamentos do NLP')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb3oH8vGzx9s",
        "outputId": "79232dd1-991b-4e37-fb5e-2336d8a0690a"
      },
      "source": [
        "palavras"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Eu', 'estou', 'aprendendo', 'sobre', 'os', 'fundamentos', 'do', 'NLP']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXiTEQOG0cGz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ5PBHFb0RkT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}